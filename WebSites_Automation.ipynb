{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Project for Automated process of Web data extraction and Monitoring**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. This script helps automatically extracted data from Qualtrics platform and save them into the specified directory. I used ChromeDrive from selenium package to aotumate this data extraction process. The script also contains several Exception Handling techniques that commonly encountered when employing this tool to do Web Scraping.\n",
    "2. After the datafiles have been stored, we unzip them and read them into pd dataframe so we could conducted subseqent merging and cleaning.\n",
    "3. We create a class to contain all the methods that we need to use for our primary purpose\n",
    "4. For current project, we have total 4 URLs to loop over. We stored them into a list and create 4 objects, then we can call the method that we defined within the class.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the Python libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import csv\n",
    "from random import randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup as bf\n",
    "from selenium import webdriver\n",
    "from time import sleep\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import time\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "import zipfile\n",
    "import os\n",
    "from selenium.common.exceptions import ElementNotInteractableException, ElementClickInterceptedException\n",
    "from selenium.common.exceptions import WebDriverException\n",
    "from datetime import datetime"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The following session help us to reach our goal of automatically \n",
    "extract all the data in the location defined by the URLs we provided**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QualtricExtract(object):\n",
    "    \n",
    "      # First Let us define objects attributes\n",
    "    def __init__(self,source,username,password,url):\n",
    "        self.dir = source \n",
    "        self.__username = username\n",
    "        self.__password = password\n",
    "        self.url = url\n",
    "        options = Options()\n",
    "        options.add_argument(\"--disable-notifications\")\n",
    "        options.add_argument(\"--headless\")\n",
    "        options.add_argument(\"start-maximized\")\n",
    "        options.add_experimental_option(\"prefs\", {\n",
    "        \"download.default_directory\": self.dir,\n",
    "        \"download.prompt_for_download\": False,\n",
    "        \"download.directory_upgrade\": True,\n",
    "        \"safebrowsing.enabled\": True\n",
    "        })\n",
    "        self.driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()),options=options)\n",
    "        self.driver.implicitly_wait(0.5)\n",
    "\n",
    "    # Create a method to let system inactive for a while\n",
    "    def timePractice(self):\n",
    "        sleep(randint(5,10))\n",
    "\n",
    "    # Create a method to perform connecting to the URLs that we provided\n",
    "    def WebConnect(self) -> bool:\n",
    "\n",
    "        WebConnect = False\n",
    "        start_time = self.get_current_time_in_mills()\n",
    "        counter = 0 \n",
    "\n",
    "       # this technique handles 'WebDrivereException'\n",
    "        while not WebConnect and not self.is_time_out(start_time, 15):\n",
    "            try:\n",
    "                self.driver.get(self.url)\n",
    "                WebConnect = True\n",
    "            except(WebDriverException) as e:\n",
    "\n",
    "                sleep(2)\n",
    "                counter += 1\n",
    "                print(\"WebConnenction failed\")\n",
    "\n",
    "        print(\"WebConnenction failed \" + str(counter) + \" times\")\n",
    "\n",
    "        return WebConnect\n",
    "\n",
    "\n",
    "\n",
    "    # Create a method that call on others to execute the process\n",
    "    def gotoualtrics(self):\n",
    "       \n",
    "        WebConnect_res = self.WebConnect()\n",
    "        \n",
    "        # Assert Error Message if Connecting failed \n",
    "        assert WebConnect_res, \"WebConnenction failed\"\n",
    "\n",
    "        self.LoginByID()\n",
    "\n",
    "        self.DownloadData()\n",
    "\n",
    "        self.teardown()\n",
    "\n",
    "\n",
    "    # Create a method to login into the URLs we provided\n",
    "    def LoginByID(self):\n",
    "        self.timePractice()\n",
    "        WebDriverWait(self.driver, 20).until(EC.visibility_of_element_located((By.ID, \"UserName\")))\n",
    "        self.__key = self.driver.find_element(By.ID, \"UserName\")\n",
    "        WebDriverWait(self.driver, 15).until(EC.visibility_of_element_located((By.ID, \"UserPassword\")))\n",
    "        self.__pasw = self.driver.find_element(By.ID, \"UserPassword\")\n",
    "        self.__key.send_keys(self.__username)\n",
    "        self.__pasw.send_keys(self.__password)\n",
    "        self.driver.find_element(By.ID,\"loginButton\").click()\n",
    "        self.timePractice()\n",
    "        \n",
    "    # Create a method that navigate us to the correct page to download the data\n",
    "    def DownloadData(self):\n",
    "\n",
    "        # Find and Click 'DATA & ANALYSIS' BUTTON\n",
    "        WebDriverWait(self.driver,20).until(EC.presence_of_element_located((By.XPATH,\n",
    "        '//*[@id=\"center\"]/div[2]/div/div/div/global-wrapper-react-header/global-wrapper-top-nav/div/nav[2]/div/ul/li[4]/a/div[1]')))\n",
    "        self.driver.find_element(By.XPATH,\n",
    "        '//*[@id=\"center\"]/div[2]/div/div/div/global-wrapper-react-header/global-wrapper-top-nav/div/nav[2]/div/ul/li[4]/a/div[1]').click()\n",
    "        \n",
    "        # The page needed to load for a while\n",
    "        sleep(2)\n",
    "\n",
    "        # Find and click the 'Export&Import' button to expand the menu\n",
    "        Export_Import_ele = WebDriverWait(self.driver,20).until(EC.presence_of_element_located((By.CSS_SELECTOR,'svg[data-icontype=\"Download\"]')))\n",
    "        \n",
    "        Export_Import_res = self.click_until_interactable(Export_Import_ele)\n",
    "        \n",
    "        assert Export_Import_res, \"Clicking the 'Export&Import' button has failed\"\n",
    "\n",
    "        \n",
    "        #  Find and Click the 'Export' button\n",
    "        Export_ele = WebDriverWait(self.driver, 20).until(EC.visibility_of_element_located((By.CSS_SELECTOR, 'div[value=\"EXPORT_DATA_ELLIPSIS\"]')))  \n",
    "        \n",
    "        Export_res = self.click_until_interactable(Export_ele)\n",
    "        \n",
    "        assert Export_res, \"Clicking the 'Export' button has failed\"\n",
    "\n",
    "        \n",
    "        # Scroll the pop up to the next button that we need\n",
    "        self.ScrollDown()\n",
    "\n",
    "\n",
    "        #  Find and Click the 'Use numeric values'\n",
    "\n",
    "        numeric_ele = WebDriverWait(self.driver,20).until(EC.presence_of_element_located((By.XPATH,'//*[@id=\"export-data-modal-body\"]/div[3]/div/fieldset/label[1]/span/input')))\n",
    "        \n",
    "        numeric_res = self.click_until_interactable(numeric_ele)\n",
    "\n",
    "        assert numeric_res, \"Clicking the 'Use numeric values' button has failed\"\n",
    "\n",
    "        \n",
    "        #  Find and Click the 'DownLoad' button\n",
    "        DownLoad_ele = WebDriverWait(self.driver,20).until(EC.presence_of_element_located((By.CSS_SELECTOR,'button[class=\"_1jL0W _aiLYE\"]')))\n",
    "        \n",
    "        DownLoad_res = self.click_until_interactable(DownLoad_ele)\n",
    "\n",
    "        assert DownLoad_res, \"Clicking the 'DownLoad' button has failed\"        \n",
    "\n",
    "        self.timePractice()\n",
    "         \n",
    "    # Create a method to scroll the page to the end, this is hardcode so it's not recommended\n",
    "    def ScrollDown(self):\n",
    "        for x in range(5):\n",
    "            self.driver.execute_script(\"window.scrollBy(0,300)\")\n",
    "            sleep(0.1)\n",
    "\n",
    "    # Create a method to wait for the vanishing of some elements, this is a technique to tackle ElementNotInteractableException \n",
    "    # when your elements are being blocked by other elements        \n",
    "    def wait_for_element_to_vanish(self, element: webdriver.remote.webelement.WebElement) -> bool:\n",
    "\n",
    "        is_displayed = element.is_displayed()\n",
    "\n",
    "        start_time = self.get_current_time_in_mills()\n",
    "\n",
    "        time_interval_in_seconds = 5\n",
    "\n",
    "        while is_displayed and not self.is_time_out(start_time,time_interval_in_seconds):\n",
    "\n",
    "            is_displayed = element.is_displayed()\n",
    "        \n",
    "        return not is_displayed\n",
    "\n",
    "\n",
    "    # Create a method to get current time in millionseconds\n",
    "    def get_current_time_in_mills(self):\n",
    "\n",
    "        td = (datetime.utcnow() - datetime(1970, 1, 1))\n",
    "\n",
    "        current_time_in_mills = (td.microseconds + (td.seconds + td.days*86400)*10**6)//10**3\n",
    "\n",
    "        return current_time_in_mills\n",
    "        \n",
    "\n",
    "    # Create a method to set up a time limit for us to try to execute some codes\n",
    "    # if the current time exceeds the end_time that we restricted to, we stop executing the codes and reporting error\n",
    "    # we use this method in a while loop to avoid the possible infinite loop\n",
    "    def is_time_out(self,original_time, time_interval_in_seconds) -> bool:\n",
    "\n",
    "        wait_time = time_interval_in_seconds * 10**3\n",
    "\n",
    "        end_time = original_time + wait_time\n",
    "        \n",
    "        return (self.get_current_time_in_mills() >= end_time)\n",
    "        \n",
    "\n",
    "\n",
    "    # Create a method to handle ElementNotInteractableException,ElementClickInterceptedException these two common exceptions\n",
    "    # It is often encountered during the element locating and clicking process, the elements have been found but not clickable\n",
    "    # it is possible that there is an another element overlay it and that element has received the click, \n",
    "    # But in our case, the Exception is not caused by this reason, we only have 'element is not clickable at point' message\n",
    "    # It is because in the URLs that we are workiing, aftere expand the previous menu, it needs several times to load the data, only after the data has been \n",
    "    # completely loaded the button we are looking for will show up\n",
    "    # The traditional Wait.until.clickable method from Expected_Condition module is not very useful in handling exceptions like this, \n",
    "    # which is due to asynchronous programming.\n",
    "    # so we create a method to handle it ourself.     \n",
    "    def click_until_interactable(self, element: webdriver.remote.webelement.WebElement) -> bool:\n",
    "\n",
    "        element_is_interactable = False\n",
    "\n",
    "        start_time = self.get_current_time_in_mills()\n",
    "\n",
    "        counter = 1\n",
    "\n",
    "        if element:\n",
    "            while not element_is_interactable and not self.is_time_out(start_time,20):\n",
    "\n",
    "                try:\n",
    "                    element.click()\n",
    "                    element_is_interactable = True\n",
    "\n",
    "                except(ElementNotInteractableException,ElementClickInterceptedException) as e:\n",
    "\n",
    "                    counter += 1\n",
    "        \n",
    "        print(\"We've tried \" + str(counter) + \" times\")\n",
    "\n",
    "        return element_is_interactable\n",
    "        \n",
    "    # create a method to close all the running session and release the memory\n",
    "    def teardown(self):\n",
    "        self.driver.quit()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Provided the information we need and execute the codes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r\"C:\\Users\\xxxxx\\Desktop\\xxxxxxx\"\n",
    "username = \"xxxxxxxxx\"\n",
    "password = \"xxxxxxxxx\"\n",
    "url_lists = ['https://peabody.az1.qualtrics.com/survey-builder/SV_a63UOQB30sRN0Wh/edit?LoginAction=EditSection',\n",
    "             'https://peabody.az1.qualtrics.com/survey-builder/SV_3JfvpNZUqGfFQC9/edit?LoginAction=EditSection',\n",
    "             'https://peabody.az1.qualtrics.com/survey-builder/SV_3dseyi0rsBznBcO/edit?LoginAction=EditSection',\n",
    "             'https://peabody.az1.qualtrics.com/survey-builder/SV_9pBhZXudyC0QaGy/edit?LoginAction=EditSection']\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    obj1 = QualtricExtract(path,username,password,url_lists[0])\n",
    "    obj1.gotoualtrics()\n",
    "    obj2 = QualtricExtract(path,username,password,url_lists[1])\n",
    "    obj2.gotoualtrics()\n",
    "    obj3 = QualtricExtract(path,username,password,url_lists[2])\n",
    "    obj3.gotoualtrics()\n",
    "    obj4 = QualtricExtract(path,username,password,url_lists[3])\n",
    "    obj4.gotoualtrics()   "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Then we create another class to Unzip all the files stored in the specified dicrectory**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Unzip(object):\n",
    "\n",
    "    dir = path # create this class variable which you could access to it by self.dir or Unzip.dir\n",
    "\n",
    "    # First to specified some attributes that we hope to get access later\n",
    "    def __init__(self):\n",
    "        self.file_list = [os.path.join(self.dir,f) for f in os.listdir(self.dir)]\n",
    "        self.time_sorted = sorted(self.file_list, key = os.path.getmtime)\n",
    "        self.zip_names = self.time_sorted[1:len(self.time_sorted)+1]\n",
    "        self.list_dfs = {}\n",
    "\n",
    "    # Create method to Unzip all the files\n",
    "    def Unzipfiles(self):\n",
    "        i = 1\n",
    "        for zip_name in self.zip_names:\n",
    "            list_ = []\n",
    "            with zipfile.ZipFile(zip_name) as myzip:\n",
    "                for file in myzip.namelist():\n",
    "                    with myzip.open(file) as infile:\n",
    "                        list_.append(pd.read_csv(infile))\n",
    "            self.list_dfs[\"Folder_\" + str(i)] = list_\n",
    "            i += 1 \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Then we create the object and call the method**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    objdf = Unzip()\n",
    "    objdf.Unzipfiles()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. objdf.list_dfs is a dictionary that we used to store all the files extrated from each zip folder as VALUE.\n",
    "2. we can unpack its items and loop over them to get what we need\n",
    "3. #NOTE# the dfs are stored in lists, objdf.list_dfs[key] would only return a list. So we need to get access to it by objdf.list_dfs[key][0], we first extracted all of them, then we stored them into a list for next step\n",
    "4. then we can assign them as different dfs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Assign the extracted DFs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = [objdf.list_dfs[key][0] for key, value in objdf.list_dfs.items()]\n",
    "SIDE1, SIDE2, ETHIC1, ETHIC2 = temp"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check Data Structure of individual dataframes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original shapes\n",
    "print(SIDE1.shape)\n",
    "print(SIDE2.shape)\n",
    "print(ETHIC1.shape)\n",
    "print(ETHIC2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The first two rows are not meaningful we need to drop them\n",
    "# DROP the first two rows and reset the index to make starting from 0\n",
    "SIDE1 = SIDE1.iloc[2:,:].reset_index(drop=True)\n",
    "SIDE2 = SIDE2.iloc[2:,:].reset_index(drop=True)\n",
    "ETHIC1 = ETHIC1.iloc[2:,:].reset_index(drop=True)\n",
    "ETHIC2 = ETHIC2.iloc[2:,:].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checked the changed shape\n",
    "print(SIDE1.shape)\n",
    "print(SIDE2.shape)\n",
    "print(ETHIC1.shape)\n",
    "print(ETHIC2.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's look at the total number of columns for these 4 data frames since we need them merge them row-wise**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am aware of that these data frames have different number of columns, \n",
    "\n",
    "so when concatenate them by row, some new columns will be introduced into the final merged data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIDE1.shape[1] + SIDE2.shape[1] + ETHIC1.shape[1] + ETHIC2.shape[1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If not considering the overlapping columns shared among 4 dfs, the total numbers are: 1061"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's find the unique column after we stored them into a list**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set([*SIDE1.columns.tolist(),*SIDE2.columns.tolist(),*ETHIC1.columns.tolist(),*ETHIC2.columns.tolist()]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If considering the overlapping columns shared among 4 dfs, the total numbers are: 643"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's merge the dfs row-wise, the pandas would automatically filled the cell with NA if there is no values entered**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Combined_df = pd.concat([SIDE1, SIDE2, ETHIC1,ETHIC2],axis=0, ignore_index=True)\n",
    "print(Combined_df.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As being confirmed in the previous code cell, pandas would only horizontally merge unique columns and fill NA for no ENTRY, and if the columns are common among dfs, pandas would vertically concatenate them."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check data info and NAs in each column**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Combined_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None) \n",
    "Combined_df.isna().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see here, some columns have more than 2000 NA vals, they are the unique columns the pandas added column-wise. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cc2a200e1e6dab10c4dc3986f0e7a998296447c993c26561a1bd050a849d8214"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
